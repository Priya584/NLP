## Gujarati Tokenizer â€“ Sentence & Word Level

This tokenizer processes Gujarati text into clean, meaningful units using regex-based rules. The tokenizer works on streaming data from the `IndicCorpV2` dataset.

---

### Sentence Tokenization

We use a custom sentence boundary detector for Gujarati that avoids incorrect splits on common patterns like dates, currency, and titles.

#### ğŸ›¡ï¸ Protected Patterns

Before splitting, we **temporarily replace** sensitive patterns with placeholders:

| Pattern | Meaning |
|--------|---------|
| `àª¤àª¾\s*\.` | Used in dates (e.g., `àª¤àª¾. 5 àª“àª—àª¸à«àªŸ`) |
| `àª°à«‚àª¾\s*\.` | Currency notation (`àª°à«‚àª¾. 500`) |
| `àª¶à«àª°à«€\s*\.` / `àª¶à«àª°à«€àª®àª¤à«€\s*\.` | Honorifics |
| `àª¡à«‰\s*\.` | Doctor title |

These are later **restored** after sentence splitting.

#### ğŸ“ Sentence Split Pattern

```python
pattern = r'(?<!\d)\.(?!\d)|[\u0964!?]'
```

**Explanation:**

- `(?<!\d)\.(?!\d)` â†’ Matches a dot (`.`) **only if itâ€™s not between digits**  
  â†’ Prevents splits on numbers like `3.14`

- `[\u0964!?]` â†’ Matches:
  - `\u0964` â†’ Danda `à¥¤` (used in Gujarati/Hindi)
  - `!` â†’ Exclamation
  - `?` â†’ Question mark

---

### Word Tokenization

We tokenize Gujarati sentences into words, punctuation, and symbols using:

```python
pattern = r'(?:àª°à«‚àª¾\.?|[$])\d[\d,.]*|\d[\d,.]*|[\u0A80-\u0AFF\w]+(?:-[\u0A80-\u0AFF\w]+)*|[$]|[.,\u0964!?;:()"\"'-]'
```

### ğŸ” Word Tokenizer Pattern Explanation

| Pattern | Matches |
|--------|---------|
| `(?:àª°à«‚àª¾\.?\|[$])\d[\d,.]*` | Currency like `àª°à«‚àª¾.500` or `$500` |
| `\d[\d,.]*` | Numbers like `12,000` or `3.14` |
| `[\u0A80-\u0AFF\w]+(?:-[\u0A80-\u0AFF\w]+)*` | Gujarati words with optional hyphenation |
| `[$]` | Standalone dollar sign |
| `[.,\u0964!?;:()"\'-]` | Punctuation marks |


---

### Output

- Sentence tokenizer stores **one sentence per row**
- Paragraph tokenizer joins tokenized sentences per paragraph
- Final data is stored in `.parquet` format using **Snappy compression**
